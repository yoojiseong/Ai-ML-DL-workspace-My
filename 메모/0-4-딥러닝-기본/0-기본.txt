텐서

파이토치 모델 연산을 위해서는 파이토치의 기본 단위인
텐서Tens를 이용해야 한다.

따라서 텐서의 종류와 연산을 잘 숙지해야만 효율적인 코드를 작성할 수 있다.

1
여러 가지 텐서

텐서Tenso는 파이토치의 기본 단위이며,
GPU 연산을 가능하게 한다.
또한 Numpy의 배열과 유사하 여 손쉽게 다룰 수 있다.

4.1 Tensor.ipynb
# 라이브러리 불러오기
import torch # Pytorch를 사용하기 위한 기본 라이브러리다.
import numpy as np # Numpy를 사용하기 위한 기본 라이브러리다. 여기서 "as np"는 numpy를 np로 짧게 표기하겠다는 뜻이다.

# 빈 텐서 생성
x = torch.empty(5,4) # 5x4 행렬 생성
print(x) # 초기화되지 않은 행렬인 경우 해당 시점에 할당된 메모리에 존재하던 값들이 초기값으로 나타난다.

tensor([[3.0573e-03, 4.3789e-41, 1.2573e-36, 3.2203e-41],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 4.3789e-41, 1.8788e+31, 1.7220e+22],
        [2.1715e-18, 8.1802e+20, 6.7941e+22, 6.7352e+22],
        [1.0374e-08, 8.3455e-10, 5.4173e-05, 1.6987e+22]])

torch는 Pytorch를 사용하기 위한 기본 라이브러리다.

torch.empty를 통해 크기가 5x4인 빈 서를 생성한다.

이때 초기화되지 않은 행렬인 경우 해당 시점에
할당된 메모리에 존재하던 값들이 초깃값으로 나타난다.

torch는 ones, zeros, empty 등 넘파이에서 사용되는
동일한 형태의 함수들을 많이 제공하고 있다.




torch.ones(3,3) # 3x3 일 행렬

tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])

torch.zeros(2,3) # 2행 영 행렬

tensor([[0., 0., 0.],
        [0., 0., 0.]])

torch.rand(5,6) # 5x6 랜덤 행렬


tensor([[0.7859, 0.0763, 0.2091, 0.6693, 0.5763, 0.1094],
        [0.5846, 0.9868, 0.7333, 0.2044, 0.7569, 0.7693],
        [0.0167, 0.9476, 0.4705, 0.6998, 0.4514, 0.9915],
        [0.2539, 0.2254, 0.9577, 0.2469, 0.1414, 0.6474],
        [0.8115, 0.0097, 0.1681, 0.9050, 0.3020, 0.7494]])



2
리스트, 넘파이 배열을 텐서로 만들기
torch.tensor를 통해 서로 변환이 가능하다.
또한 torch.FloatTensor, torch.LongTensor와 같 이
구체적인 텐서 타입을 정의할 수도 있다.


l = [13,4] # 리스트 생성
r = np.array([4,56,7]) # 넘파이 배열 생성
print(l)
print("l 타입: ",type(l))
print(r)
print("r 타입: ",type(r))


[13, 4]
l 타입:  <class 'list'>
[ 4 56  7]
r 타입:  <class 'numpy.ndarray'>


torch.tensor(l) # 리스트를 텐서로 쉽게 변환할 수 있다.


tensor([13,  4])

torch.tensor(r) #넘파이 배열을 텐서로 쉽게 변환할 수 있다.

tensor([ 4, 56,  7])


torch.FloatTensor(r)

tensor([ 4., 56.,  7.])

3
텐서의 크기와 타입 확인하기

x.size()

torch.Size([5, 4])

x.size()[1] # .size()는 텐서의 크기를 확인할 수 있으며 매우 자주 사용된다.
4

type(x) # type은 Python에서 사용되는 모든 것들을 종류를 보여준다.

torch.Tensor


4
텐서의 덧셈

x = torch.rand(2,2) # 2x2 랜덤 행렬
y = torch.rand(2,2) # 2x2 랜덤 행렬
print(x)
print(y)

tensor([[0.7270, 0.6586],
        [0.8363, 0.7826]])
tensor([[0.5011, 0.4992],
        [0.3587, 0.3367]])

x+y # 두 텐서의 합


tensor([[1.2281, 1.1578],
        [1.1950, 1.1194]])


torch.add(x,y) # 두 텐서의 합의 또 다른 표현

tensor([[1.2281, 1.1578],
        [1.1950, 1.1194]])


y.add(x) # 두 텐서의 합의 또 다른 표현이지만 이는 y에 x를 더한다는 의미다.

tensor([[1.2281, 1.1578],
        [1.1950, 1.1194]])


print("원래 y: ", y)
y.add_(x)
print("y=y+x: ",y)

# y = y+x
# y.add_는 y에 x를 더한 값을 y에 대체한다.(inplace 방식)

원래 y:  tensor([[0.5011, 0.4992],
        [0.3587, 0.3367]])
y=y+x:  tensor([[1.2281, 1.1578],
        [1.1950, 1.1194]])


5
 텐서의 크기 변환하기

x = torch.rand(8,8) # 8x8 랜덤 행렬
print(x.size())
print(f"x torch.rand(8.8) 출력 결과 : \n {x}")

torch.Size([8, 8])
x torch.rand(8.8) 출력 결과 :
 tensor([[0.5377, 0.7500, 0.1650, 0.7036, 0.9245, 0.4306, 0.0930, 0.9544],
        [0.2912, 0.1620, 0.9544, 0.5292, 0.4332, 0.2670, 0.2973, 0.2626],
        [0.4617, 0.4220, 0.2627, 0.4498, 0.4928, 0.0693, 0.4962, 0.2681],
        [0.8206, 0.4972, 0.3182, 0.1971, 0.0326, 0.6334, 0.1201, 0.9383],
        [0.3167, 0.0526, 0.8267, 0.3863, 0.7182, 0.8093, 0.4739, 0.1989],
        [0.8218, 0.1146, 0.7926, 0.9996, 0.7145, 0.0829, 0.7912, 0.9100],
        [0.9765, 0.4094, 0.9641, 0.6274, 0.2277, 0.0116, 0.6510, 0.6715],
        [0.7295, 0.6994, 0.1508, 0.2969, 0.6733, 0.8887, 0.6130, 0.2695]])


a = x.view(64) # 크기를 바꿔주는 view 8x8 -> 64
print(a) # 1차원 배열
print(a.size())

tensor([0.5377, 0.7500, 0.1650, 0.7036, 0.9245, 0.4306, 0.0930, 0.9544, 0.2912,
        0.1620, 0.9544, 0.5292, 0.4332, 0.2670, 0.2973, 0.2626, 0.4617, 0.4220,
        0.2627, 0.4498, 0.4928, 0.0693, 0.4962, 0.2681, 0.8206, 0.4972, 0.3182,
        0.1971, 0.0326, 0.6334, 0.1201, 0.9383, 0.3167, 0.0526, 0.8267, 0.3863,
        0.7182, 0.8093, 0.4739, 0.1989, 0.8218, 0.1146, 0.7926, 0.9996, 0.7145,
        0.0829, 0.7912, 0.9100, 0.9765, 0.4094, 0.9641, 0.6274, 0.2277, 0.0116,
        0.6510, 0.6715, 0.7295, 0.6994, 0.1508, 0.2969, 0.6733, 0.8887, 0.6130,
        0.2695])
torch.Size([64])


b = x.view(-1,4,4) # -1은 원래 크기가 되게 하는 값 8x8 -> -1x4x4 즉, 4x4x4이다.
print(b.size())

# 따라서 -1은 원래 크기가 되게 하는 값이 자동으로 지정되기 때문에 한 번만 사용할 수 있다.
# 예를 들어 x.view(-1,-1,4)와 같은 선언은 오류가 난다.




b = x.view(-1,4,4) # -1은 원래 크기가 되게 하는 값 8x8 -> -1x4x4 즉, 4x4x4이다.
print(b.size())

# 따라서 -1은 원래 크기가 되게 하는 값이 자동으로 지정되기 때문에 한 번만 사용할 수 있다.
# 예를 들어 x.view(-1,-1,4)와 같은 선언은 오류가 난다.


6
텐서에서 넘파이로 만들기

x = torch.rand(8,8)
y = x.numpy() # .numpy()로 매우 간단하게 넘파이 배열로 만들 수 있다.
print(type(y))
print(y.shape)
print(y)


<class 'numpy.ndarray'>
(8, 8)
[[0.5709364  0.11609852 0.95291775 0.28650123 0.501598   0.227382
  0.2466296  0.1920119 ]
 [0.98393595 0.18818337 0.09458131 0.8040099  0.31956118 0.97682863
  0.46157575 0.31338626]
 [0.7727331  0.1983146  0.20972812 0.32066846 0.67760426 0.2807778
  0.12267405 0.5925363 ]
 [0.92377865 0.21922112 0.09791118 0.8843601  0.82349986 0.86520964
  0.91565704 0.8196784 ]
 [0.7168688  0.02564013 0.99750465 0.54105073 0.5373754  0.6474285
  0.40419585 0.61724824]
 [0.54449826 0.19795907 0.82005906 0.21230316 0.65778565 0.5336954
  0.82429    0.04982787]
 [0.4949342  0.06208777 0.6672973  0.3285522  0.4076947  0.6057169
  0.73487025 0.9688425 ]
 [0.4277625  0.23273945 0.40280944 0.36754847 0.02782035 0.7766795
  0.391764   0.30150485]]


type(y)

7 단일 텐서에서 값으로 뽑아내기

loss = torch.ones(1)


print(loss)
print(loss.item()) # .item()은 손실 함숫값과 같이 숫자가 하나인 텐서를 텐서가 아닌 값으로 만들어 준다.

tensor([1.])
1.0

=============================================================================

역전파

모델 파라미터의 최적화는 미분의 성질과 연쇄 법칙을 기반으로 한
역전파를 통해 진행된다.

역전파는 모델이 복잡할수록 계산 과정이 복잡해져
코드를 직접 구현하기에는 어려움이 있다.

따라서 파이토치는 간단하게 사용할 수 있는 다양한 최적화 방법을 제공하고 있다.

그래디언트 텐서

일반적으로 인공 신경망의 최적화라는 것은
손실 함수의 최솟값Gobalminimum이 나오게 하는
신경망의 최 적 가중치를 찾는 과정이다.

따라서 최적화를 위해 변화량을 나타내는 미분은 필수적인 요소다.
이 때 깊은 인공 신경망의 구조는 입력값이 들어와
다중의 층을 지나 출력값을 산출하는
합성 함수 형 태입을 알 수 있다.

따라서 미분의 성질과
연쇄 법칙 Chanrule을 통해 원하는
변수에 대한 미분값을 계산 할 수 있다.

다만 층이 깊어지거나 구조가 복잡할수록 계산이
복잡해지기 때문에 사람이 직접 계산 하기는 매우 힘들다.

파이토치는 앞서 언급한 일련에 계산 과정을 자동으로 해주는
자동 미분 계산 함수를 제공하고 있다.

따라서 최적화 과정인 역전파를 쉽게 작성할 수 있다.



샘플코드_예시
Backpropagation.ipynb

# 라이브러리 불러오기
import torch

# requires_grad=True는 해당 텐서를 기준으로 모든 연산들을 추적할 수 있게 하는 옵션이다.
# 즉, x에 대해서 연쇄 법칙을 이용한 미분이 가능하다는 것이다.
x = torch.ones(2,2, requires_grad=True)
print(x)

tensor([[1., 1.],
        [1., 1.]], requires_grad=True)

# y는 x에 대한 식, z는 y에 대한 식, res는 z에 대한 식이다. 따라서 이는 합성함수의 개념으로써
# x에 대해서 표현 및 미분이 가능하다.
y = x+1
z = 2*y**2
res = z.mean()
print("y: ", y)
print("z: ", z)
print("Result: ", res)
# grad_fn=..은 추적이 잘 되고 있다는 의미다.

y:  tensor([[2., 2.],
        [2., 2.]], grad_fn=<AddBackward0>)
z:  tensor([[8., 8.],
        [8., 8.]], grad_fn=<MulBackward0>)
Result:  tensor(8., grad_fn=<MeanBackward0>)


res.backward()
# res를 기준으로 역전파를 진행하겠다는 의미다.

# 역으로 식을 써내려 가보자.
# res = (z_1 + .. +z_4)/4
# z_i = 2 y_i **2
# z_i = 2(x_i+1)**2
# d(res)/dx_i = x_i + 1


print(x)
print(x.grad)
# x.grad는 backward()가 선언 된 변수를 기준으로 미분을 한다. 즉 d(res)/dx를 계산한다.
# #d(res)/dx_i = x_i + 1


tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
tensor([[2., 2.],
        [2., 2.]])


requires grad=True는
해당 텐서를 기준으로 모든 연산들을 추적하여
그래디언트 Gradient라고 하는 미분값의 모임(배열)을 계산할 수 있게 한다.

즉, x에 대해서 연쇄 법칙을 이용한 미분이 가능하다 는 것이다.

다음 예시를 보면
y는 x에 대한 식,
z는 y에 대한 식.
r은 2에 대한 식이다.

따라서 이는 합성 함수의 개념으로써
최종 함수 r은 x에 대해서 표현 및 미분이 가능하다.

여기서 수학적인 이해가 필요한 부분이 있는데
미분을 한다는 것은 미분이 가능한 함수라는 것이고,
함수 라는 것은 미분하려는 변수가 함수의 조건을 만족해야 한다는 의미다.
함수의 조건은 정의역에 속하는 주 어진 값 x는
오직 하나에 대한 1값이 치역에 존재해야 한다.

따라서 y와 Z는 함수의 조건에 만족하지 않고
일련의 계산 과정이기 때문에
y와 2를 x에 대해서 미분을 하려고 했을 때 에러가 난다.

따라서 모델의 최적화를 위해 단일값이 나오는 손실 함수를 정의하는 것이다.


자동 미분 - 선형회귀식

샘플코드_예시

Autograd.ipynb

자동 미분을 위해 과거에는 Tensor를 덮어씌워 사용하는 Variable을 사용했다.
하지만 현재 텐서는 자동 미분을 위한 기능을 직접 제공하기 때문에
Variable를 사용하지 않고 Tensor를 바로 이용한다.

import torch
from matplotlib import pyplot as plt
x = torch.FloatTensor(range(5)).unsqueeze(1)
y = 2*x + torch.rand(5,1)
num_features = x.shape[1]
print(x.shape, y.shape)
torch.Size([5, 1]) torch.Size([5, 1])


이해를 돕기 위해 일변수 데이터를 생성하여 이용한다.
즉 (x,y)인 형태로 2차원 상에서 표현 이 가능한 데이터다.

torch. FloatTensor(range(5)는 리스트 range(5)를 이용해 서로 만든다.
이때 원래 크기는 1차원 인 torch Size(5)이라서 행렬 계산을 위해
2차원 배열로 만들어 준다.

이때 unsqueeze(1)는 1번째 위치의 차원를 늘려주는 역할을 하여
최종적으로 x의 크기는 torch. Size(5, 1)이 된다

(만약 unsquccze(O) 이면 크기는 torch,Size(1. 5)가 된다).
y는 실제 값으로 임의로 5개를 만들어 준다.


p83
 다음으로 변수의 개수를 저장하는 num fealures를 만든다.
x의 크기는 torch.Size(15, 1)이므로 인스턴스의 개수가 5개이고
변수(피체)의 개수가 1개인 데이터다.

따라서 x,shape은 변수의 개수 가 된다.
  w= torch.rand(num features, 1, requires_grad=True)
  b= torch.randn(1, requires_grad=True)

® 선형식은 y=xW+b으로 표현된다. 따라서 w는 5x1 데이터와 곱할 수 있어야 하며,
예측값이 하나로 나와야 하므로
크기가 1(피쳐수)xI(출력값 크기)인 배열로 정의하자. 따라서 Xw는 5x1이 된다.

⑦ 편향 b는 모든 인스턴스에 동일한 숫자를 더해주는 것이므로 크기가 1인 서로 정의한다.
우리의 목표는 xW+b가 잘 예측을 할 수 있는 w와 b를 찾는 것이다.
초깃값에 대한 좋은 정보가 있 을 경우에는 좋은 값으로 초깃값을
설정한다면 수렴이 빠르고 정확도도 높아질 수 있지만,
모르는 경우에는 초깃값을 무작위로 준다.

이 예시에서는 torch.randn을 이용한다. ③,4의 텐서와
6,⑦ 텐 서의 가장 큰 차이는 requires grad=True 유무다.

데이터는 변하지 않는 값으로서 업데이트가 필요 하지 않는
반면 w, b값은 역전파를 통해 최적값을 찾는 것이므로
w, b에 requires grad를 True로 활 성화시킨다.

가중치를 업데이트하는 최적화 방법은 매우 다양하다.
그중 가장 널리 사용되는 방법이 경사하강법 이다.

경사하강법 Gradlent cescent은 목적 함수인 손실 함수를 기준으로
그래디언트를 계산하여 변수를 최 석화하는 기법이다.

이 예시에서는 가장 기본적인 최적화 방법인 확률적 경사하강법을 사용한다.

® learning_rate = 1e-3
optimizer = torch.optim.SGD([W, b], Ir=learning_rate)

,© torch.optim.SGD 내부에 변수를 리스트로 묶어 넣어주고
적절한 학습률 Learingrate을 정하여 자 동으로 가중치와 편향을 업데이트한다.

# 매 에폭마다 손실 함수값을 저장하기 위해 빈 리스트 loss stack = 를 생성한다.
loss_stack = []
# 학습 반복 수를 1001로 한다.
for epoch in range(1001):

# 최적화는 계산을 누적시키기 때문에 매 에폭마나 누적된 값을 optimizer zero grad0을 통해 초기 화한다.
	optimizer.zero_grad()

	#회귀식 모델을 이용하여 예측값을 산출한다.
	y_hat = torch.matmul(x, w) + b

	# 예측값과 실제값을 이용하여 손실 함수를 계산한다.
	#여기서 사용된 함수는 Mean Square ETrorMSE이다.
	loss = torch.mean((y_hat-y)**2)
	# 역전파의 기준을 손실 함수로 정한다.
	loss.backward()
	# 미리 정의한 optimizer를 이용하여 최적화를 시행한다.
	optimizer.step()

	#그래프를 그리기 위해 손실 함수값만 1oss Stack에 하나씩 넣는다.
	# item)을 사용하지 않으면 1oss 텐서 전체를 저장하게 된다.
	loss_stack.append(loss.item())

	#에폭이 100으로 나눠 떨어질 때마다 손실 함수값을 출력한다.
	if epoch % 100 == 0:
	print(f'Epoch (epoch):(loss.item?*)
Output:
Epoch 0:33.04575729370117
.... 중략 ....
Epoch 1000:0.06831956654787064


with torch.no_grad():
v_hat =torch.matmul(x, w)+b
, 최종 학습된 w, b로 예측값을 산출한다.
이때 최적화를 사용하지 않으므로 requires grad를 비 활성화한다.
이때 with torch.no_grad0:를 이용하여 구문 내부에 있는
requires_grad가 작동하지 않 도록 할 수 있다.


plt.figure(figsize=(10, 5))
plt.subplot(121)
plt.plot(loss_stack)
plt.title("Loss")
plt.subplot(122)
plt.plot(x, y,'.b')
pit.plot(x, y_hat, 'r-')
plt.legend(l'ground truth', prediction'])
plt.title("Prediction")
plt.show()

conda install torchvision -c pytorch

43데이터 불러오기
메모리와 같은 하드웨어 성능의 한계 등의 이유로
한 번에 전체 데이터를 모델에 주어 학습하기 힘 들기 때문에
일반적으로 배치 형태의 묶음으로 데이터를 나누어 모델 학습에 이용한다.
또한 모델 을 학습할 때 데이터의 특징과 사용 방법에 따라
학습 성능의 차이가 날 수 있다.

따라서 데이터를 배치 형태로 만드는 법과
데이터를 전처리하는 방법에 대해서 알아본다.

4.3.1 파이토치 제공 데이터 사용

Data Loader(기본편).ipynb

#파이토치 기본 라이브러리
import torch

# 이미지와 관련된 파이토치 라이브러리
import torchvision

#이미지 전처리 기능들을 제공하는 라이브러리
import torchvision.transforms as tr

#데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리
from torch.utils.data import DataLoader, Dataset
import numpy as p
import matplotlib.pyplot as plt




# torchvision.datasets에서 제공하는 CIFAR10 데이터를 불러온다.
# root에는 다운로드 받을 경로를 입력한다.
# train=Ture이면 학습 데이터를 불러오고 train=False이면 테스트 데이터를 불러온다.
# 미리 선언한 전처리를 사용하기 위해 transform=transf을 입력한다.

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)

tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.
예시에서는 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환한다.
만약 원본 이미지의 너비, 높이가 다를 경우 너비,
높이를 각각 지 정을 해야 하기 때문에 t.Resize(16,16)이라고 입력해야 한다.

torchvision.datasets에서 제공하는 CIFAR10 데이터를 불러온다
(CIFAR10은 클래스가 10개인 이 미지 데이터 세트다).
 root에는 다운로드받을 경로를 입력한다.
 train=True이면 학습 데이터를 불러 오고
 train=Falsc이면 테스트 데이터를 불러온다.

마지막으로 미리 선언한 전처리를 사용하기 위해 transform=transt을 입력한다.




# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태다.
# (이미지, 라벨)
# trainset[0]은 학습 데이터의 첫 번째 데이터로
# 이미지 한 장과 라벨 숫자 하나가 저장되어 있다.
# 즉, trainset[0][0]은 이미지이며 trainset[0][1]은 라벨이다.

print(trainset[0][0].size())

# 현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널 수를 말하고
# 16x16은 이미지의 너비와 높이를 의미한다.
# 일반적인 컬러 사진은 RGB 이미지이기 때문에 채널이 3개 이고
# (너비)x(높이)x(채널 수)로 크기가 표현된다.

# 하지만 파이토치에서는 이미지 한 장이 (채널 수)x(너비)x(높이)으로
# 표현되니 유의하도록 한다.

# DataLoader는 데이터를 미니 배치 형태로 만들어 준다.
# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.
trainloader = DataLoader(trainset, batch_size=50, shuffle=True)
testloader = DataLoader(testset, batch_size=50, shuffle=False)

즉, batch_size=50, shuffle=True은
무작위로 데이터를 섞어 한 번 에 50개의 이미지를 묶은 배치로 제공하겠다는 의미다.

len(trainloader)
Output: 1000

CIFAR10의 학습 이미지는 50000장이고 배치 사이즈가 50장이므로
1000은 배치의 개수가 된다.

images, labels = iter(trainloader).next()
print(images.size())

Output: torch.Size([50, 3, 16, 161)

배치 이미지를 간단히 확인하기 위해 파이썬에서 제공하는
iter와 next 함수를 이용한다.

이를 통 해 trainloader의 첫 번째 배치를 불러올 수 있다.
1 배치 사이즈는 (배치 크기)×(채널 수)×(너비) (높이)를 의미한다.
즉, 배치 하나에 이미지 50개가 잘 들어가 있음을 알 수 있다.


# iter, next를 이용해 일부 데이터를 확인할 수 있다.
images, labels = iter(trainloader).next()
print(images.size())

# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.
# (배치 크기)x(채널 수)x(너비)x(높이)
torch.Size([50, 3, 16, 16])
oneshot = images[1].permute(1,2,0).numpy()
plt.figure(figsize=(2,2))
plt.imshow(oneshot)
plt.axis("off")
plt.show()


4.3.2 같은 클래스 별로 폴더를 정리한 경우

from google.colab import drive
drive.mount('/content/gdrive')


cd/content/gdrive/My Drive/busanit501-1234

# 데이터가 같은 클래스 별로 미리 폴더를 정리 된 경우,
# ImageFolder의 1줄 선언으로 개인 데이터를 사용할 수 있다.
# 별도의 라벨링이 필요 없으며 폴더 별로 자동으로 라벨링을 한다.
# 예를 들어 class 폴더에 tiger, lion 폴더
# (./class/tiger와 ./class/lion)를 미리 만든다.
# 다음으로 ImageFolder에 상위 폴더
# ./class를 입력하면 이미지와 라벨이 정리 되어 데이터를 불러온다.

# 128x128 이미지 크기 변환 후 텐서로 만든다.
transf = tr.Compose([tr.Resize(128),tr.ToTensor()])

# 커스텀 데이터 불러온다.
trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)

# 데이터를 미니 배치 형태로 만들어 준다.
trainloader = DataLoader(trainset, batch_size=2, shuffle=False)
dataiter = iter(trainloader)
images, labels = dataiter.next()
print(images.size(),labels)
torch.Size([2, 3, 134, 128]) tensor([0, 0])


4.3.3 정리되지 않은 커스텀 데이터 불러오기

# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정하다.

# (이미지 수)x(너비)x(높이)x(채널 수)
train_images = np.random.randint(256,size=(100,32,32,3))/255
train_labels = np.random.randint(2,size=(100,1)) # 라벨 수

# 이미지 전처리 작업이 필요할 경우 openCV와 같은 라이브러리를 이용하여
# 이 곳에서 작업할 수도 있다.

# 이 단계에서 전처리하는 것을 선호한다.
# 그 이유는 torchvision.transforms 라이브러리 보다
# OpenCV, SciPy와 같은 라이브러리가 더 많은 전처리 기술을 제공하며
# 이미지를 미리 처리해 놓고 전처리 된 이미지를 살펴보면서
# 작업하는 것을 좋아하기 때문이다.

# 따라서 사용 목적과 편의성에 맞게 본인이 전처리를 어디서 할 지 정하면 될 것이다.

#......
#......
#......
#train_images, train_labels = preprocessing(train_images, train_labels)
#......
#......
#......

print(train_images.shape, train_labels.shape)
(100, 32, 32, 3) (100, 1)
"""
from torch.utils.data import Dataset

class MyDataset(Dataset):

    def __init__(self):

    def __getitem__(self, index):

    def __len__(self):

이 양식을 통으로 가지고 다니자!!

"""

class TensorData(Dataset):

    def __init__(self, x_data, y_data):
		# # 이미지 데이터를 FloatTensor로 변형
        self.x_data = torch.FloatTensor(x_data)
		# (이미지 수)x(너비)x(높이)x(채널 수) -> (배치 크기)x(채널 수)x(너비)x(높이)
        self.x_data = self.x_data.permute(0,3,1,2)
        self.y_data = torch.LongTensor(y_data) # 라벨 데이터를 LongTensor로 변형
        self.len = self.y_data.shape[0] # 클래스 내의 들어 온 데이터 개수

    def __getitem__(self, index):
        return self.x_data[index], self.y_data[index] # 뽑아 낼 데이터를 적어준다.

    def __len__(self):
        return self.len # 클래스 내의 들어 온 데이터 개수

# 파이토치에서는 (배치 크기)x(채널 수)x(너비)x(높이)
# 데이터가 사용 되므로 원래 데이터 (이미지 수)x(너비)x(높이)x(채널 수)를 변경해야만 한다.

# permute에서 0(이미지 수), 1(너비),2 (높이), 3(채널 수)을
# 0(이미지 수), 3(채널 수), 1(너비),2 (높이)로 바꿔주는 것이기 때문에
# .permute(0,3,1,2)을 사용하는 것이다.

train_data = TensorData(train_images,train_labels) # 텐서 데이터 불러오기
train_loader = DataLoader(train_data, batch_size=10, shuffle=True) # 미니 배치 형태로 데이터 갖추기




4.3.4 커스텀 데이터와 커스텀 전처리 사용하기
import torch
import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리
from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리
import numpy as np # 넘파이 기본 라이브러리
import matplotlib.pyplot as plt
# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정하다.
# glob -> PIL, openCV ..
train_images = np.random.randint(256,size=(100,32,32,3))/255 # (이미지 수)x(너비)x(높이)x(채널 수)
train_labels = np.random.randint(2,size=(100,1)) # 라벨 수
# 전처리 기술을 직접 만들어 보자.
# 이 때 위 기본 양식과 같이 사용하기 위해 call 함수를 사용한다.
# def __call__ 내의 원하는 전처리 작업을 프로그래밍 할 수 있다.

# 1. 텐서 변환
class ToTensor:
    def __call__(self, sample):
        inputs, labels = sample
        inputs = torch.FloatTensor(inputs) # 텐서로 변환
        inputs = inputs.permute(2,0,1) # 크기 변환
        return inputs, torch.LongTensor(labels) # 텐서로 변환

# 2. 선형식
class LinearTensor:

    def __init__(self, slope=1, bias=0):
        self.slope = slope
        self.bias = bias

    def __call__(self, sample):
        inputs, labels = sample
        inputs = self.slope*inputs + self.bias # ax+b 계산하기
        return inputs, labels

# 2. CutOut
class CutOut:

    def __init__(self, ratio=.5):
        self.ratio = int(1/ratio)

    def __call__(self, sample):
        inputs, labels = sample
        active = int(np.random.randint(0, self.ratio, 1))

        if active == 0:
            _, w, h = inputs.size()
            min_len = min(w, h)
            box_size = int(min_len//4)
            idx = int(np.random.randint(0, min_len-box_size, 1))
            inputs[:,idx:idx+box_size,idx:idx+box_size] = 0

        return inputs, labels


# .....
# 추가로 계속 원하는 전처리를 정의하자.
# .....
# 3.3에서 사용한 양식을 그대로 사용하되 전처리 작업을 할 수 있도록 transform을 추가한다.
class MyDataset(Dataset):

    def __init__(self, x_data, y_data, transform=None):

        self.x_data = x_data # 넘파이 배열이 들어온다.
        self.y_data = y_data # 넘파이 배열이 들어온다.
        self.transform = transform
        self.len = len(y_data)
        self.tensor = ToTensor()

    def __getitem__(self, index):
        sample = self.x_data[index], self.y_data[index]

        if self.transform:
            sample = self.transform(sample) #self.transform이 None이 아니라면 전처리를 작업한다.
        else:
            sample = self.tensor(sample)

        return sample

    def __len__(self):
        return self.len
#trans = tr.Compose([ToTensor(),LinearTensor(2,5)]) # 텐서 변환 후 선형식 2x+5 연산
trans = tr.Compose([ToTensor(),CutOut()])
dataset1 = MyDataset(train_images,train_labels, transform=trans)
train_loader1 = DataLoader(dataset1, batch_size=10, shuffle=True)

# ToTensor()와 tr.ToTensor()의 차이
# 앞 서 사용한 tr.ToTensor()는 import torchvision.transforms as tr를 이용한 파이토치 메소드를 이용한 것이고
# ToTensor()는 위에서 정의 된 메소드를 사용한 것이다.
images1, labels1 = iter(train_loader1).next()
print(images1.size()) # 배치 및 이미지 크기 확인
torch.Size([10, 3, 32, 32])
import torchvision
def imshow(img):
    plt.figure(figsize=(10,100))
    plt.imshow(img.permute(1,2,0).numpy())
    plt.show()
imshow(torchvision.utils.make_grid(images1,nrow=10))

4.3.5 커스텀 데이터와 파이토치 제공 전처리 사용하기
# torchvision.transforms에서 제공하는 전처리 기술을 사용한다.
# torchvision.transforms은 입력 이미지가 일반적으로 PILImage 타입이나 텐서일 경우에 동작한다.
# 현재 데이터는 넘파이 배열이다. 따라서 텐서 변환 후 tr.ToPILImage()을 이용하여 PILImage 타입으로 만들어 준다.
# __call__을 이용한 기본 구조는 동일하다.

class MyTransform:

    def __call__(self, sample):
        inputs, labels = sample
        inputs = torch.FloatTensor(inputs)
        inputs = inputs.permute(2,0,1)
        labels = torch.FloatTensor(labels)

        transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor()])
        final_output = transf(inputs)

        return final_output, labels
dataset2 = MyDataset(train_images,train_labels, transform=MyTransform())
train_loader2 = DataLoader(dataset2, batch_size=10, shuffle=True)
images2, labels2 = iter(train_loader2).next()
imshow(torchvision.utils.make_grid(images2,nrow=10))
print(images2.size()) # 배치 및 이미지 크기 확인

torch.Size([10, 3, 128, 128])


4.3.6 커스텀 데이터와 파이토치 제공 전처리 사용하기


파이토치는 전처리 함수들을 제공하여 매우 편리하게 사용할 수 있다.
하지만 이미지의 경우 PIL-Image 타입이거나 Tensor 타입일 때 사용이 가능하다.
또한 제공하지 않는 기능에 대해서는 직접 구현이 필요하다.
이번 시에서는 전처리 클래스 2개를 직접 정의하고 사용한다.

class ToTensor:
	def __call__(self, sample):
		inputs, labels = sample
		inputs = torch.FloatTensor(inputs)
		inputs = inputs.permute(2,0,1)
		return inputs, torch.LongTensor(labels)

텐서 변환 전처리 클래스를 정의한다.
전처리는 MyDataset 클래스의 Sample을 불러와 작업하기
때 문에 call 함수를 이용한다.

ToTensor:는 입력 데이터를 텐서 데이터로 변환해 주고
학습에 맞 는 크기로 변환하는 작업을 담당한다.

torch.FloatTensor와 torch, LongTensor를 이용해
서로 변환하고 Permute(2,0.1)을 이용 해 크기를 변경한다.

여기서 유의할 점은 call 함수는
입력값을 하나씩 불러오기 때문에 per-mute(0.3.1,2)이 아닌
permute(2.0.1)로 코드를 작성한다.

콜함수,
__call__ -> 객체를 함수처럼 호출 가능,
예) obj = ToTensor(sample)

obj(sample) 호출시 -> __call__ 함수 호출하여 사용.

다음은 Cutout 전처리 클래스를 정의한다.
CutOut은 이미지 내부에 무작위로 사각형 영역을 선택 하여
0으로 만드는 데이터 증식 방법이다.

class CutOut:

	#  ToTensor와 다르게 외부에서 CutOut 발생 비율을 받기 위해
	# init 함수를 사용하여 ratio를 받는다.
	# 기본 ratio는 0.5로 세팅하면 불러온 이미지에 대해서 50% 확률로 CutOut를 발현한다.
    def __init__(self, ratio=.5):
        self.ratio = int(1/ratio)

    # call_ 함수에서는 샘플을 받는다
    def __call__(self, inputs):

		#active는 정수를 뽑는다.
		# 50%일 경우 0과 1 중 하나를 뽑게 되고 1과0중
		# 0이면 CutOut를 발현하고 0 이 아니면 원본을 그대로 내보내게 된다.
        active = int(np.random.randint(0, self.ratio, 1))

        if active == 0:
			# 다음은 이미지의 너비와 높이를 받아 최솟값을 구한다.
			# inputs의 크기는 (채널 수, 너비, 높이) 이므로
			# 등식 왼쪽에 있는 출력 개수를 맞춰야 하기 때문에
			# 변수를 3개 선언해야 한다.
			# 하지만 채널 수는 필요없기 때문에 _ 를 통해 값을 저장하지 않는다.
            _, w, h = inputs.size()
            min_len = min(w, h)

			#이 코드에서는 CutOut의 크기를 길이의 최솟값의 25%로 설정한다.
            box_size = int(min_len//4)

			#idx를 통해 CutOut 박스의 죄측 상단 꼭지점 위치를 정해준다.
            idx = int(np.random.randint(0, min_len-box_size, 1))

			# 해당 정사각형 영역의 값을 0으로 대체한다
			#(당연히 코드를 변형하여 다른 모양으로도 만들 수 있다).
            inputs[:,idx:idx+box_size,idx:idx+box_size] = 0

        return inputs






# 3.3에서 사용한 양식을 그대로 사용하되 전처리 작업을 할 수 있도록 transform을 추가한다.
class MyDataset(Dataset):

    def __init__(self, x_data, y_data, transform=None):

        self.x_data = x_data # 넘파이 배열이 들어온다.
        self.y_data = y_data # 넘파이 배열이 들어온다.
        self.transform = transform
        self.len = len(y_data)
        self.tensor = ToTensor()

    def __getitem__(self, index):
        sample = self.x_data[index], self.y_data[index]

        if self.transform:
			# #self.transform이 None이 아니라면 전처리를 작업한다.
            sample = self.transform(sample)
        else:
            sample = self.tensor(sample)

        return sample

    def __len__(self):
        return self.len

class MyTransform:

    def __call__(self, sample):
        inputs, labels = sample
        inputs = torch.FloatTensor(inputs)
        inputs = inputs.permute(2,0,1)
        labels = torch.FloatTensor(labels)

        transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor(), CutOut()])
        final_output = transf(inputs)

        return final_output, labels

전처리 적용
dataset3 = MyDataset(train_images,train_labels, transform=MyTransform())
train_loader3 = DataLoader(dataset3, batch_size=10, shuffle=True)
images3, labels3 = iter(train_loader3).next()
imshow(torchvision.utils.make_grid(images3,nrow=10))
print(images3.size()) # 배치 및 이미지 크기 확인

torch.Size([10, 3, 128, 128])

전처리 미적용
dataset3 = MyDataset(train_images,train_labels)
train_loader3 = DataLoader(dataset3, batch_size=10, shuffle=True)
images3, labels3 = iter(train_loader3).next()
imshow(torchvision.utils.make_grid(images3,nrow=10))
print(images3.size()) # 배치 및 이미지 크기 확인

torch.Size([10, 3, 32, 32])
CIFAR100 데이터와 커스텀 전처리 사용
transf = tr.Compose([tr.Resize(128), tr.ToTensor(), CutOut()])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
  0%|          | 0/170498071 [00:00<?, ?it/s]
Extracting ./data/cifar-10-python.tar.gz to ./data
trainloader = DataLoader(trainset, batch_size=10, shuffle=True)
images, labels = iter(trainloader).next()
imshow(torchvision.utils.make_grid(images,nrow=10))
print(images.size()) # 배치 및 이미지 크기 확인

















