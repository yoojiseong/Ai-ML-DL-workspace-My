CHAPTER 3 지도 학습

지도_학습 예시

A는 중요한 시험을 위해 시험공부를 하고 있다.
문제집을 사서 그 안에 들어 있는 다수의 문제들 을 풀고 답을 내놓고
채점을 통해 실제 정답과 비교하면서 무엇이 틀렸는지 파악하고
다시 점수를 올리기 위해 자신의 지식을 정리하고
다시 문제를 풀어 답을 내놓고 실제 정답과 비교하는 것을 반 복하면서
실력을 쌓아간다.
이와 같은 학습 방법이 지도 학습 Supersed learmins이다.


비지도_학습

학습 중 정답지를 사용하지 않고 문제만을 풀어
문제의 패턴을 파악하는 방법을 비지도 학습 Unsupersedlearning이라고 한다.


지도 학습 흐름


문제집(데이터)->모델(A)
1->정답 작성(예측값)
2->채점(손실 함수)
3->정답 작성(실제값)
4->지식 수정(모델 최적화)
->1,2,3,반복 과정

지도 학습의 장점은

학습 과정에서 정답을 사용하기 때문에 일반적으로 비지도 학습보다 성능이 좋다.

단점,

지도 학습은 데이터에 대응하는 라벨 혹은 목푯값target vale이라고
불리는 실제 정답을 가지고 있어야 하기 때문에
실제값이 없을 경우에는 모델 구축 이전에 실제값을 정의해야만 한다.

예를 들어
우리가 고양이, 개, 호랑이 등의 동물 10,00여 종의 사진을
각각 500,00장씩 가지고 있 다고 가정.
우리가 이 데이터를 가지고 지도 학습을 하기 위해서는
어떤 사진이 어떤 동물인지 표시를 하는 라벨링 작업labelmg
또는 anotaion을 하거나 폴더 정리를 거쳐야만 한다.

이때 많은 시간과 비용이 소모될 수 있다.
또한 라벨링을 잘못할 가능성이 있기 때문에 데이터 관리를 잘해야 한다.
따라서
지도 학습을 위해 기본적으로 정확히 정답이 표기된 데이터를 가지고 있어야 한다.


기본적인 지도 학습 과정
목적은 예측을 잘 하는 좋은 모델을 만드는 것이다.
모델은 가중치와 편향을 통해 예측값을 산출하기 때문에
좋은 모델이라는 의미는 문제에 적합한 가중치와 편향을 가진 모델이라는 뜻이다.

따라서 지도 학습의 목표는 학습을 통해 적절한 모델의 가중치와 편향을 찾는 것이다.

처음 학습 시 에는 무작위로 가중치와 편향을 정하여 예측값을 산출한다.

따라서 예측값이 얼마나 정확한지를 판단할 필요가 있다.

여기에 사용되는 개념이 손실 함수다.

손실 함수Lossb Functon는
실제값과 예측값이 얼마나 차이가 나는지를 측정하는 척도로써
문제에 따라 적절한 손실 함수를 정해주는 것이 중요하다.

일반적으로 손실 함숫값이 작다는 의미는 실제값과 예측값의 차이가 작다는 뜻으로
학습을 잘하고 있다는 것이고.

반대로 함숫값이 크면 학습이 효과적이지 못하다는 의미다.

따라서 현재 예측을 통해 얻은 손실값 보다
다음 학습 시 더 작은 손실 함숫값을 얻기 위해
이 전 가중치와 편향을
좀 더 적절한 가중치와 편향으로 최적화 opimitaton하게 된다.

가중치와 편향의 업 데이트는 손실 함수의 최적화 문제로 귀결된다.

즉. 손실 함수 L이 최소가 되게 하는 가중치와 편향 을 구하게 되는데
이때 필요한 것이 미분 개념이다.

미분 계산으로 구성된 역전파Back-propagation를 통해
손실 함수의 최소 지점을 찾게 된다.

이 과정에서 구해진 새로운 가중치와 편향으로
다시 예측값을 구해서 손실 함수를 계산하고

역전파를 통해 다시 가중치와 편향을 업데이트하는 일련의 과정을 반복하게 된다.


그림 예시.
input X ->
1- Model(f(x)) -> Output -> Loss (y,y1)
2- Loss (y,y1) , 최소값 , 웨이트 업데이트 ->  Model(f(x))
1,2 반복


소스코드 예시


# 데이터 정의
train_data = ...# 데이터를 준비한다(학습 데이터).
train_loader = ...

# 반복 학습
for epoch in range(num_epochs): # 전체 데이터에 대한 반복 학습
	for inputs, labels in train_loader: # 입력값과 실제값 - 배치 데이터
		...
		optimizer.zero_grad() # 최적화 초기화

		# 모델이 데이터를 받아 예측값을 산출한다(인공신경망 모델).
		outputs=model(inputs) # 예측값 산출 (2)

		# 예측값과 실제값을 이용해 손실 함수를 계산한다(손실 함수).
		loss= criterion(outputs, labels)# 손실 함수 계산(3)

		# 손실 함수를 기준으로 가중치와 편향을 최적화한다(최적화 기법).
		loss.backward() # 손실 함수 기준으로 역전파 설정 (4)
		optimizer.step() # 모델 가중치 업데이트 (5)
		...


배치(Batch) 데이터
많은 양의 데이터를 한 번에 계산하면 메모리 문제가 발생할 수 있다.
따라서 데이터를 분할해서 학습에 사용한다.
예를 들어 5000개의 학습 데이터가 있다면 20개씩 나눠
250번의 내부 for문을 돌게 된다.

즉, 내부 for문이 다 돌면 5000개의 데이터를 한 번 학습했다는 의미다.
최종적으로 외부 for문을 통해
5000개의 데이터를 여러 번 반복 학습한다.


지도 학습의 종류
지도 학습 문제 중
회귀 문제 Regresion와
분류 문제 classifcation를 가장 쉽게 접할 수 있다.

회귀 문제는 우리가 원하는 결괏값이 연속적인 변수인 것을 예측하는 문제다.

예를 들어
집값 예측, 온도 예측이 있다.

반면에
분류 문제는 우리가 원하는 결값이 클래스s라고 하는
유한한 모임으로 분류되는 문제다.

예를 들어
질병 예측(양성(1) 또는 음성(0), 만족도 예측(1, 2, 3점)이 있다.

여기서 만족도를 1, 2, 3이라고 구분 짓는 것을 라벨링laeling이라고 하며
1, 2, 3 숫자들을 라벨 이라 한다.
만약 1, 2, 3을 0과 1로만 구성된 벡터 (1,0,0), (0,1,0), (0,0, 1)로
표현하는 방법을 원-핫 인코딩 one-hotencoding이라고 부르며,
표현된 벡터를 원-핫 벡터one-hotvecto라고 한다.

회귀 문제
  보스턴 집값 예측 - 집값
  주가 예측 - 종가

분류 문제
  MNIST - (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)
  CIFAR10 - 객체(비행기, 승용차, 새, )
  유방암 진단 - 양성, 음성
  와인 품질 예측 - 평점(1, 2, 3, 4, 5점 중)

대표적인 데이터 소스
  Sklearn 데이터셋 라이브러리
  Pytorch 데이터셋 라이브러리
  UCI https://archive.ics.uci.edu
  Kaggle https://www.kaggle.com



데이터 세트 분할
시험 대비를 위해 문제집 100권을 샀다고 가정하자.
그리고 100권 선체를 1000번 반복해서 문제를 풀면서 지식을 쌓았다면
우리는 100권 안에 있는 모든 문제를 다 맞을 수 있을 것이다.
그렇다면 지 금 가지고 있는 문제집에서 100점을 맞았다고 해서

"실제 시험에서 100점을 맞을 수 있을까?"라는 의문을 가질 수 있다.

물론 많은 문제집을 풀었기 때문에 높은 점수를 기대할 수 있지만
장담은 못할 것이다.

따라서 현재 까지 공부한 실력을 검증할 수 있도록 모의고사를 보면 좋다.
즉, 100권 중 80권은 지도 학습 방법으 로 공부를 하고
나머지 20권은 학습 이후에 검증을 목적으로 풀어 보는 것이다.

예를 들어
80권을 학 습하여 100점을 맞고 학습에 사용하지 않은 20권에서는
50점을 맞았다면 공부 방법(학습)이 잘못된 것이고,
20권을 풀었을 때 90점을 맞았다면 학습을 잘했다고
자신의 실력을 판단할 수 있을 것이다.

이렇듯, 보편적으로 용도에 따라 데이터를 분할하여 사용하게 되며
학습에 사용되는 데이터를 학습 데이터 ,
평가에 사용되는 데이터를 평가 데이터 라고 부른다.

하지만 평가 데이터로부터 얻은 결과를 기준으로
가장 좋은 모델을 선택한다면
평가 데이터 외 새로운 데이터에 대해서
예측 을 잘못할 수 있기 때문에

학습, 검증 Valdation, 평가용으로 데이터를 3 종류로 나누기도 한다.
데이터 분할 비율은 정해진 것이 없지만

일반적으로 학습 : 평가 = 7: 3 (5 : 5, 6 : 4) 혹은
학습 : 검증 :평가 = 6: 2 : 2로 나누며

데이터 셋이 큰 경우에는 학습 데이터 비율을 8, 9까지 놓기도 한다.

데이터를 분할하는 방법은 무작위 추출 Random ampig,
총화 추출 Randon Stratfed samping,
교차 검증 Crossvalidation 등 다양한 방법들이 있다.

기본적으로 무작위 방식으로 데이터를 나누며
sklearn 라이브러리를 통해 쉽게 적용할 수 있다.
가장 중요한 것은 어떠한 방식으로
데이터를 학습, 검증, 평가 세트로 나누더라도
데 이터가 절대 중복으로 들어가서는 안된다.

소스코드_예시
import numpy as np
from sklearn.model_selection import train_test_split

X, y = np.arange(1000).reshape((100, 10)), np.arange(100)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

(70, 10) (70,) (30, 10) (30,)

test size=0.3인 경우에는
평가 데이터가 전체의 30%이므로 100개 중 무작위로 골라
70개가 학습 데이터가 되고
나머지 30개가 평가 데이터가 된다.
이와 같은 방법으로 학습, 검증. 평가 데이터로 나눌 수도 있다.

참고로 train test split의 입력 데이터는 리스트, numpy 배열,
scipy-sparse 행렬, pandas 데이터프레임 형태를 허용한다.



X, y = np.arange(1000).reshape((100, 10)), np.arange(100)
X_train, X_test, y_train, y_test =
train_test_split(X, y, test_size=0.4, random_state=0)

X_test, X_val, y_test, y_val =
train_test_split(X_test, y_test, test_size=0.5, random_state=1)

print(X_train.shape, y_train.shape, X_val.shape,
y_val.shape, X_test.shape, y_test.shape)

(60, 10) (60,) (20, 10) (20,) (20, 10) (20,)

만약에 학습, 김증, 평가 데이터의 비율이 6 : 2 : 2라고 한다면
학습 데이터와 평가 데이터를 6 : 4로 나눈 후
평가 데이터를 다시 평가 네이터와 검증 데이터 비율이 5 : 5로 나누면 결과적으로
6: 2:2라는 비율을 얻게 된다.


